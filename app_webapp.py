import os
import uvicorn
import requests
import logging

from fastapi import FastAPI, HTTPException, Body
from src.backend.pydantic_models import ResearchPaperQuery
from src.constants import ENDPOINT_URLS

app = FastAPI(title="Research Assistant API")
logger = logging.getLogger('uvicorn.error')

# Root endpoint just to check if the API is running.
@app.get(ENDPOINT_URLS['web_app']['path'], summary="Root", description="Root endpoint.")
async def root():
    return {"message": "Hello from the AI Research Paper Assistant"}

# Handles research queries.
@app.post(ENDPOINT_URLS['web_app']['additional_paths']['query'], summary="Submit a research query", description="Returns an answer generated by the system.")
async def query_system(query_request:ResearchPaperQuery=Body(...)):
    try:
        # Call the RAG endpoint
        logger.info("Calling RAG endpoint")
        RAG_URL = f"http://{ENDPOINT_URLS['rag']['base_url']}{ENDPOINT_URLS['rag']['path']}"
        RAG_response = requests.post(url=RAG_URL, json={"message": query_request.message})
        responses = RAG_response.json()["responses"]

        logger.info(f"Successfully called the RAG endpoint. Received {len(responses)} responses.")

        logger.info("Calling LLM inference endpoint")
        LLM_INFERENCE_URL = f"http://{ENDPOINT_URLS['llm_inference']['base_url']}{ENDPOINT_URLS['llm_inference']['path']}"
        requests.post(url=LLM_INFERENCE_URL, json={"prompt": query_request.message})

        logger.info(f"Successfully called the system.")

        return {"answer": None}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
if __name__ == "__main__":
    uvicorn.run("app_frontend:app", host="localhost", port=8000, reload=True)
